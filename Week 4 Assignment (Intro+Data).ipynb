{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# The Battle of Neighborhood (Week 1)"}, {"metadata": {}, "cell_type": "markdown", "source": "# Applied Data Science Capstone by IBM/Coursera\n\n\n\n### 1. Introduction: Business Problem\nThe aim of this project is to help people planning to open a new coffee shop in Toronto to chose the best location. The three main features in making such decisions are the income and population of neighborhood as well as the competitors already existed in the same region. Data science tools will be used to analyze data and focus on the most populated borough and explore its neighborhoods and the 10 msot common venues in each neighborhood so that the best neighborhood where coffee shop is not amongst the most common venues can be selected.\n\n\n\n\n### 2. Data Collection and Analysis\nTo provide the stakeholders the necessary information I will combine Toronto's 2016 Census data that contains Population, Average income per neighborhood with Foursquare API to collect competitors' information on the same neighborhoods.\n\nToronto's census data for public is available at the following website: https://www.toronto.ca/city-government/data-research-maps/open-data/open-data-catalogue/#8c732154-5012-9afe-d0cd-ba3ffc813d5a"}, {"metadata": {}, "cell_type": "markdown", "source": "## 2.1 Import necessary libraries"}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np\nimport pandas as pd\n\n#Importing Matplot lib and associated packages to perform Data Visualisation and Exploratory Data Analysis\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n#Importing folium to visualise Maps and plot based on Lat and Lng\n!pip install folium\nimport folium\n\n#Requests to request web pages by making get requests to FourSquare REST Client\nimport requests\n\n#To normalise data returned by FourSquare API\nfrom pandas.io.json import json_normalize\n\n#Importing KMeans from SciKit library to Classify neighborhoods into clusters\nfrom sklearn.cluster import KMeans\n\nprint('Libraries imported')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## 2.2 Data Collection from Website\u00b6\n"}, {"metadata": {}, "cell_type": "code", "source": "\n# Use 2016 Toronto census data to collect Toronto's income per neighborhood\ncsv_path='https://www.toronto.ca/ext/open_data/catalog/data_set_files/2016_neighbourhood_profiles.csv'\ndf = pd.read_csv(csv_path,encoding='latin1')\nprint('Data loaded')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# display data\ndf.head(11)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n# Collecting neighborhoods names\nNeighbourhoods = list(df.columns.values)\nNeighbourhoods = Neighbourhoods[5:]\nprint(Neighbourhoods)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## 2.3 Create a New Dataset with Neighborhood Name, Population and Income\n"}, {"metadata": {}, "cell_type": "code", "source": "Toronto_df = pd.DataFrame(index=Neighbourhoods, columns=[\"Population\",\"Income\"])\nfor index, row in Toronto_df.iterrows():\n    Toronto_df.at[index, 'Population'] = df[index][2]\n    Toronto_df.at[index, 'Income'] = df[index][2264]\n    \nToronto_df.sort_values('Income')\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}